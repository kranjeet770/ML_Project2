{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(r'C:\\Users\\kranj\\ML\\Project_2\\census_income.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education.num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital.status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital.gain  capital.loss  hours.per.week  native.country       Y  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', dtype('int64'), 73, 0),\n",
       " ('workclass', dtype('O'), 9, 0),\n",
       " ('fnlwgt', dtype('int64'), 21648, 0),\n",
       " ('education', dtype('O'), 16, 0),\n",
       " ('education.num', dtype('int64'), 16, 0),\n",
       " ('marital.status', dtype('O'), 7, 0),\n",
       " ('occupation', dtype('O'), 15, 0),\n",
       " ('relationship', dtype('O'), 6, 0),\n",
       " ('race', dtype('O'), 5, 0),\n",
       " ('sex', dtype('O'), 2, 0),\n",
       " ('capital.gain', dtype('int64'), 119, 0),\n",
       " ('capital.loss', dtype('int64'), 92, 0),\n",
       " ('hours.per.week', dtype('int64'), 94, 0),\n",
       " ('native.country', dtype('O'), 42, 0),\n",
       " ('Y', dtype('O'), 2, 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(df_train.columns,df_train.dtypes,df_train.nunique(),df_train.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>education.num</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10th</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>933</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11th</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12th</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>433</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st-4th</th>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5th-6th</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7th-8th</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9th</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assoc-acdm</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assoc-voc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bachelors</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctorate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HS-grad</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Masters</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Preschool</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prof-school</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Some-college</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "education.num  1    2    3    4    5    6     7    8      9     10    11  \\\n",
       "education                                                                  \n",
       " 10th           0    0    0    0    0  933     0    0      0     0     0   \n",
       " 11th           0    0    0    0    0    0  1175    0      0     0     0   \n",
       " 12th           0    0    0    0    0    0     0  433      0     0     0   \n",
       " 1st-4th        0  168    0    0    0    0     0    0      0     0     0   \n",
       " 5th-6th        0    0  333    0    0    0     0    0      0     0     0   \n",
       " 7th-8th        0    0    0  646    0    0     0    0      0     0     0   \n",
       " 9th            0    0    0    0  514    0     0    0      0     0     0   \n",
       " Assoc-acdm     0    0    0    0    0    0     0    0      0     0     0   \n",
       " Assoc-voc      0    0    0    0    0    0     0    0      0     0  1382   \n",
       " Bachelors      0    0    0    0    0    0     0    0      0     0     0   \n",
       " Doctorate      0    0    0    0    0    0     0    0      0     0     0   \n",
       " HS-grad        0    0    0    0    0    0     0    0  10501     0     0   \n",
       " Masters        0    0    0    0    0    0     0    0      0     0     0   \n",
       " Preschool     51    0    0    0    0    0     0    0      0     0     0   \n",
       " Prof-school    0    0    0    0    0    0     0    0      0     0     0   \n",
       " Some-college   0    0    0    0    0    0     0    0      0  7291     0   \n",
       "\n",
       "education.num    12    13    14   15   16  \n",
       "education                                  \n",
       " 10th             0     0     0    0    0  \n",
       " 11th             0     0     0    0    0  \n",
       " 12th             0     0     0    0    0  \n",
       " 1st-4th          0     0     0    0    0  \n",
       " 5th-6th          0     0     0    0    0  \n",
       " 7th-8th          0     0     0    0    0  \n",
       " 9th              0     0     0    0    0  \n",
       " Assoc-acdm    1067     0     0    0    0  \n",
       " Assoc-voc        0     0     0    0    0  \n",
       " Bachelors        0  5355     0    0    0  \n",
       " Doctorate        0     0     0    0  413  \n",
       " HS-grad          0     0     0    0    0  \n",
       " Masters          0     0  1723    0    0  \n",
       " Preschool        0     0     0    0    0  \n",
       " Prof-school      0     0     0  576    0  \n",
       " Some-college     0     0     0    0    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df_train['education'],df_train['education.num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop([\"education\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Y\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Y\"]=(df_train[\"Y\"]==' >50K').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['workclass', 'marital.status', 'occupation', 'relationship', 'race',\n",
       "       'sex', 'native.country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols=df_train.select_dtypes([\"object\"]).columns\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass\n",
      "marital.status\n",
      "occupation\n",
      "relationship\n",
      "race\n",
      "sex\n",
      "native.country\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    freq=df_train[col].value_counts()\n",
    "    k=freq.index[freq>500][:-1]\n",
    "    for cat in k:\n",
    "        name=col+'_'+cat\n",
    "        df_train[name]=(df_train[col]==cat).astype(int)\n",
    "    del df_train[col]\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', dtype('int64'), 73, 0),\n",
       " ('fnlwgt', dtype('int64'), 21648, 0),\n",
       " ('education.num', dtype('int64'), 16, 0),\n",
       " ('capital.gain', dtype('int64'), 119, 0),\n",
       " ('capital.loss', dtype('int64'), 92, 0),\n",
       " ('hours.per.week', dtype('int64'), 94, 0),\n",
       " ('Y', dtype('int32'), 2, 0),\n",
       " ('workclass_ Private', dtype('int32'), 2, 0),\n",
       " ('workclass_ Self-emp-not-inc', dtype('int32'), 2, 0),\n",
       " ('workclass_ Local-gov', dtype('int32'), 2, 0),\n",
       " ('workclass_ ?', dtype('int32'), 2, 0),\n",
       " ('workclass_ State-gov', dtype('int32'), 2, 0),\n",
       " ('workclass_ Self-emp-inc', dtype('int32'), 2, 0),\n",
       " ('marital.status_ Married-civ-spouse', dtype('int32'), 2, 0),\n",
       " ('marital.status_ Never-married', dtype('int32'), 2, 0),\n",
       " ('marital.status_ Divorced', dtype('int32'), 2, 0),\n",
       " ('marital.status_ Separated', dtype('int32'), 2, 0),\n",
       " ('occupation_ Prof-specialty', dtype('int32'), 2, 0),\n",
       " ('occupation_ Craft-repair', dtype('int32'), 2, 0),\n",
       " ('occupation_ Exec-managerial', dtype('int32'), 2, 0),\n",
       " ('occupation_ Adm-clerical', dtype('int32'), 2, 0),\n",
       " ('occupation_ Sales', dtype('int32'), 2, 0),\n",
       " ('occupation_ Other-service', dtype('int32'), 2, 0),\n",
       " ('occupation_ Machine-op-inspct', dtype('int32'), 2, 0),\n",
       " ('occupation_ ?', dtype('int32'), 2, 0),\n",
       " ('occupation_ Transport-moving', dtype('int32'), 2, 0),\n",
       " ('occupation_ Handlers-cleaners', dtype('int32'), 2, 0),\n",
       " ('occupation_ Farming-fishing', dtype('int32'), 2, 0),\n",
       " ('occupation_ Tech-support', dtype('int32'), 2, 0),\n",
       " ('relationship_ Husband', dtype('int32'), 2, 0),\n",
       " ('relationship_ Not-in-family', dtype('int32'), 2, 0),\n",
       " ('relationship_ Own-child', dtype('int32'), 2, 0),\n",
       " ('relationship_ Unmarried', dtype('int32'), 2, 0),\n",
       " ('relationship_ Wife', dtype('int32'), 2, 0),\n",
       " ('race_ White', dtype('int32'), 2, 0),\n",
       " ('race_ Black', dtype('int32'), 2, 0),\n",
       " ('sex_ Male', dtype('int32'), 2, 0),\n",
       " ('native.country_ United-States', dtype('int32'), 2, 0),\n",
       " ('native.country_ Mexico', dtype('int32'), 2, 0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(df_train.columns,df_train.dtypes,df_train.nunique(),df_train.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 39)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>Y</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-not-inc</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Husband</th>\n",
       "      <th>relationship_ Not-in-family</th>\n",
       "      <th>relationship_ Own-child</th>\n",
       "      <th>relationship_ Unmarried</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>sex_ Male</th>\n",
       "      <th>native.country_ United-States</th>\n",
       "      <th>native.country_ Mexico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education.num  capital.gain  capital.loss  hours.per.week  Y  \\\n",
       "0   39   77516             13          2174             0              40  0   \n",
       "1   50   83311             13             0             0              13  0   \n",
       "2   38  215646              9             0             0              40  0   \n",
       "3   53  234721              7             0             0              40  0   \n",
       "4   28  338409             13             0             0              40  0   \n",
       "\n",
       "   workclass_ Private  workclass_ Self-emp-not-inc  workclass_ Local-gov  \\\n",
       "0                   0                            0                     0   \n",
       "1                   0                            1                     0   \n",
       "2                   1                            0                     0   \n",
       "3                   1                            0                     0   \n",
       "4                   1                            0                     0   \n",
       "\n",
       "            ...            relationship_ Husband  relationship_ Not-in-family  \\\n",
       "0           ...                                0                            1   \n",
       "1           ...                                1                            0   \n",
       "2           ...                                0                            1   \n",
       "3           ...                                1                            0   \n",
       "4           ...                                0                            0   \n",
       "\n",
       "   relationship_ Own-child  relationship_ Unmarried  relationship_ Wife  \\\n",
       "0                        0                        0                   0   \n",
       "1                        0                        0                   0   \n",
       "2                        0                        0                   0   \n",
       "3                        0                        0                   0   \n",
       "4                        0                        0                   1   \n",
       "\n",
       "   race_ White  race_ Black  sex_ Male  native.country_ United-States  \\\n",
       "0            1            0          1                              1   \n",
       "1            1            0          1                              1   \n",
       "2            1            0          1                              1   \n",
       "3            0            1          1                              1   \n",
       "4            0            1          0                              0   \n",
       "\n",
       "   native.country_ Mexico  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24720\n",
       "1     7841\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,cross_val_score,train_test_split,KFold\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_train,ld_test=train_test_split(df_train,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_train.reset_index(drop=True,inplace=True)\n",
    "ld_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1=ld_train.drop([\"Y\"],axis=1)\n",
    "y_train1=ld_train[\"Y\"]\n",
    "x_test1=ld_test.drop([\"Y\"],axis=1)\n",
    "y_test1=ld_test[\"Y\"]\n",
    "x_train2=df_train.drop([\"Y\"],axis=1)\n",
    "y_train2=df_train[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutoff(real,train_score):\n",
    "    cutoffs=np.linspace(0.01,0.99,98)\n",
    "    KS_all=[]\n",
    "    for cutof in cutoffs:\n",
    "        predicted=(train_score>cutof).astype(int)\n",
    "        TP=((real==1) & (predicted==1)).sum()\n",
    "        FN=((real==1) & (predicted==0)).sum()\n",
    "        FP=((real==0) & (predicted==1)).sum()\n",
    "        TN=((real==0) & (predicted==0)).sum()\n",
    "        \n",
    "        P=TP+FN\n",
    "        N=TN+FP\n",
    "        \n",
    "        KS=TP/P-FP/N\n",
    "        KS_all.append(KS)\n",
    "    return cutoffs[KS_all==max(KS_all)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results,n_top=3):\n",
    "    for i in range(1,n_top+1):\n",
    "        candidates=np.flatnonzero(results[\"rank_test_score\"]==i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f}    Std:{1:.5f}\".format(results[\"mean_test_score\"][candidate],results[\"std_test_score\"][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr1=LogisticRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'class_weight':['balanced',None],\n",
    "       'penalty':[\"l1\",\"l2\"],\n",
    "       \"C\":np.linspace(start=0.01,stop=100,num=10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'class_weight': ['balanced', None], 'penalty': ['l1', 'l2'], 'C': array([1.000e-02, 1.112e+01, 2.223e+01, 3.334e+01, 4.445e+01, 5.556e+01,\n",
       "       6.667e+01, 7.778e+01, 8.889e+01, 1.000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search=GridSearchCV(lr1,param_grid=params,cv=10,scoring=\"roc_auc\")\n",
    "grid_search.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank 1\n",
      "Mean validation score: 0.908    Std:0.00502\n",
      "Parameters: {'C': 33.339999999999996, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "\n",
      "Model with rank 2\n",
      "Mean validation score: 0.908    Std:0.00503\n",
      "Parameters: {'C': 55.559999999999995, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "\n",
      "Model with rank 3\n",
      "Mean validation score: 0.908    Std:0.00502\n",
      "Parameters: {'C': 66.67, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "\n",
      "Model with rank 4\n",
      "Mean validation score: 0.908    Std:0.00503\n",
      "Parameters: {'C': 44.449999999999996, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "\n",
      "Model with rank 5\n",
      "Mean validation score: 0.908    Std:0.00504\n",
      "Parameters: {'C': 11.12, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(grid_search.cv_results_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=33.339999999999996, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1=grid_search.best_estimator_\n",
    "lr1.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43432989690721646"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs=lr1.predict_proba(x_test1)[:,1]\n",
    "mycutoff=cutoff(y_test1,test_probs)\n",
    "mycutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8201600843951002"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes=(mycutoff<=test_probs).astype(int)\n",
    "score=roc_auc_score(y_test1,test_classes)\n",
    "model_scores.append([\"LogisticRegression\",score])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=33.339999999999996, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.fit(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "dt2=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2={\"class_weight\":[\"balanced\",None],\n",
    "        \"criterion\":[\"entropy\",\"gini\"],\n",
    "        \"max_depth\":[None,5,10,15,20,30,50,70],\n",
    "        \"min_samples_split\":[2,5,10,15,20],\n",
    "        \"min_samples_leaf\":[1,2,5,10,15,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          fit_params=None, iid=True, n_iter=15, n_jobs=1,\n",
       "          param_distributions={'class_weight': ['balanced', None], 'criterion': ['entropy', 'gini'], 'max_depth': [None, 5, 10, 15, 20, 30, 50, 70], 'min_samples_split': [2, 5, 10, 15, 20], 'min_samples_leaf': [1, 2, 5, 10, 15, 20]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search2=RandomizedSearchCV(dt2,param_distributions=params2,cv=10,scoring=\"roc_auc\",n_iter=15)\n",
    "random_search2.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank 1\n",
      "Mean validation score: 0.897    Std:0.00596\n",
      "Parameters: {'min_samples_split': 15, 'min_samples_leaf': 20, 'max_depth': 15, 'criterion': 'gini', 'class_weight': None}\n",
      "\n",
      "Model with rank 2\n",
      "Mean validation score: 0.893    Std:0.00735\n",
      "Parameters: {'min_samples_split': 2, 'min_samples_leaf': 15, 'max_depth': 15, 'criterion': 'gini', 'class_weight': 'balanced'}\n",
      "\n",
      "Model with rank 3\n",
      "Mean validation score: 0.891    Std:0.00546\n",
      "Parameters: {'min_samples_split': 5, 'min_samples_leaf': 20, 'max_depth': 70, 'criterion': 'entropy', 'class_weight': None}\n",
      "\n",
      "Model with rank 4\n",
      "Mean validation score: 0.887    Std:0.00598\n",
      "Parameters: {'min_samples_split': 10, 'min_samples_leaf': 10, 'max_depth': 15, 'criterion': 'entropy', 'class_weight': None}\n",
      "\n",
      "Model with rank 5\n",
      "Mean validation score: 0.875    Std:0.00675\n",
      "Parameters: {'min_samples_split': 10, 'min_samples_leaf': 10, 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search2.cv_results_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=20, min_samples_split=15,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2=random_search2.best_estimator_\n",
    "dt2.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20195876288659795"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs=dt2.predict_proba(x_test1)[:,1]\n",
    "mycutoff=cutoff(y_test1,test_probs)\n",
    "mycutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8167600833708879"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes=(test_probs>=mycutoff).astype(int)\n",
    "score=roc_auc_score(y_test1,test_classes)\n",
    "model_scores.append([\"DecisionTreeClassifier\",score])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt2.fit(x_train2,y_train2)\n",
    "dotfile=open(\"mytree.dot\",\"w\")\n",
    "tree.export_graphviz(dt2,out_file=dotfile,feature_names=df_train.columns[:][:-1],class_names=[\"0\",\"1\"],proportion=True)\n",
    "dotfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf3=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 39)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "params3={\"n_estimators\":[100,200,300,500,700,1000],\n",
    "        \"max_features\":[2,5,10,15,20,30,35],\n",
    "        \"bootstrap\":[True,False],\n",
    "        \"class_weight\":[None,\"balanced\"],\n",
    "        \"criterion\":[\"entropy\",\"gini\"],\n",
    "        \"max_depth\":[None,5,10,15,20,30,50,70],\n",
    "        \"min_samples_leaf\":[1,2,5,10,15,20],\n",
    "        \"min_samples_split\":[2,5,10,15,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 37.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [100, 200, 300, 500, 700, 1000], 'max_features': [2, 5, 10, 15, 20, 30, 35], 'bootstrap': [True, False], 'class_weight': [None, 'balanced'], 'criterion': ['entropy', 'gini'], 'max_depth': [None, 5, 10, 15, 20, 30, 50, 70], 'min_samples_leaf': [1, 2, 5, 10, 15, 20], 'min_samples_split': [2, 5, 10, 15, 20]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search3=RandomizedSearchCV(rf3,param_distributions=params3,n_iter=10,verbose=1,n_jobs=-1,scoring=\"roc_auc\",cv=10)\n",
    "random_search3.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank 1\n",
      "Mean validation score: 0.919    Std:0.00376\n",
      "Parameters: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 5, 'max_depth': 70, 'criterion': 'gini', 'class_weight': 'balanced', 'bootstrap': True}\n",
      "\n",
      "Model with rank 2\n",
      "Mean validation score: 0.918    Std:0.00446\n",
      "Parameters: {'n_estimators': 500, 'min_samples_split': 15, 'min_samples_leaf': 20, 'max_features': 15, 'max_depth': 15, 'criterion': 'entropy', 'class_weight': None, 'bootstrap': True}\n",
      "\n",
      "Model with rank 3\n",
      "Mean validation score: 0.918    Std:0.00482\n",
      "Parameters: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 20, 'max_depth': 15, 'criterion': 'gini', 'class_weight': None, 'bootstrap': True}\n",
      "\n",
      "Model with rank 4\n",
      "Mean validation score: 0.918    Std:0.00391\n",
      "Parameters: {'n_estimators': 1000, 'min_samples_split': 20, 'min_samples_leaf': 15, 'max_features': 5, 'max_depth': 15, 'criterion': 'entropy', 'class_weight': None, 'bootstrap': False}\n",
      "\n",
      "Model with rank 5\n",
      "Mean validation score: 0.917    Std:0.00443\n",
      "Parameters: {'n_estimators': 700, 'min_samples_split': 15, 'min_samples_leaf': 15, 'max_features': 15, 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'bootstrap': False}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search3.cv_results_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=70, max_features=5,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=2,\n",
       "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=300, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf3=random_search3.best_estimator_\n",
    "rf3.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46463917525773196"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs=rf3.predict_proba(x_test1)[:,1]\n",
    "mycutoff=cutoff(y_test1,test_probs)\n",
    "mycutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8247676958294072"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes=(test_probs>=mycutoff).astype(int)\n",
    "score=roc_auc_score(y_test1,test_classes)\n",
    "model_scores.append([\"RandomForestClassifier\",score])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=70, max_features=5,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=2,\n",
       "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=300, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf3.fit(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbm4=GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "params4={\"n_estimators\":[50,100,200,500,700,1000],\n",
    "         \"learning_rate\":[0.001,0.005,0.01,0.05,0.1,0.4,0.8,1],\n",
    "         \"max_depth\":[1,2,3,4,5,6],\n",
    "         \"subsample\":[0.5,0.8,1],\n",
    "         \"max_features\":[2,5,10,15,20,30,35]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [50, 100, 200, 500, 700, 1000], 'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1, 0.4, 0.8, 1], 'max_depth': [1, 2, 3, 4, 5, 6], 'subsample': [0.5, 0.8, 1], 'max_features': [2, 5, 10, 15, 20, 30, 35]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search4=RandomizedSearchCV(gbm4,scoring=\"roc_auc\",param_distributions=params4,cv=5,n_iter=10,n_jobs=-1)\n",
    "random_search4.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank 1\n",
      "Mean validation score: 0.928    Std:0.00389\n",
      "Parameters: {'subsample': 0.8, 'n_estimators': 700, 'max_features': 20, 'max_depth': 4, 'learning_rate': 0.05}\n",
      "\n",
      "Model with rank 2\n",
      "Mean validation score: 0.925    Std:0.00443\n",
      "Parameters: {'subsample': 1, 'n_estimators': 50, 'max_features': 20, 'max_depth': 5, 'learning_rate': 0.4}\n",
      "\n",
      "Model with rank 3\n",
      "Mean validation score: 0.922    Std:0.00376\n",
      "Parameters: {'subsample': 0.8, 'n_estimators': 100, 'max_features': 10, 'max_depth': 4, 'learning_rate': 0.1}\n",
      "\n",
      "Model with rank 4\n",
      "Mean validation score: 0.920    Std:0.00381\n",
      "Parameters: {'subsample': 0.5, 'n_estimators': 50, 'max_features': 5, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "\n",
      "Model with rank 5\n",
      "Mean validation score: 0.915    Std:0.00369\n",
      "Parameters: {'subsample': 1, 'n_estimators': 1000, 'max_features': 20, 'max_depth': 3, 'learning_rate': 0.005}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search4.cv_results_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.05, loss='deviance', max_depth=4,\n",
       "              max_features=20, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=700,\n",
       "              presort='auto', random_state=None, subsample=0.8, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm4=random_search4.best_estimator_\n",
    "gbm4.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20195876288659795"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs=gbm4.predict_proba(x_test1)[:,1]\n",
    "mycutoff=cutoff(y_test1,test_probs)\n",
    "mycutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8365396088532918"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes=(test_probs>=mycutoff).astype(int)\n",
    "score=roc_auc_score(y_test1,test_classes)\n",
    "model_scores.append([\"GradientBoostingClassifier\",score])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.05, loss='deviance', max_depth=4,\n",
       "              max_features=20, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=700,\n",
       "              presort='auto', random_state=None, subsample=0.8, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm4.fit(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "xgb5=XGBClassifier(objective=\"binary:logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "params5={\"learning_rate\":[0.001,0.005,0.01,0.05,0.1,0.3,0.5],\n",
    "           \"gamma\":[i/10.0 for i in range(0,5)],\n",
    "           \"max_depth\":[2,3,4,5,6,7,8],\n",
    "           \"min_child_weight\":[1,2,5,10,15],\n",
    "           \"max_delta_step\":[0,1,2,5,10],\n",
    "           \"subsample\":[i/10.0 for i in range(5,10)],\n",
    "           \"cosample_bytree\":[i/10.0 for i in range(5,10)],\n",
    "           \"cosample_bylevel\":[i/10.0 for i in range(5,10)],\n",
    "           \"reg_lambda\":[1e-5,1e-2,0.1,1,100],\n",
    "           \"reg_alpha\":[1e-5,1e-2,0.1,1,100],\n",
    "           \"scale_pos_weight\":[1,2,3,4,5,6,7,8,9],\n",
    "           \"n_estimators\":[100,500,700,1000]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "          fit_params=None, iid=True, n_iter=15, n_jobs=-1,\n",
       "          param_distributions={'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1, 0.3, 0.5], 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4], 'max_depth': [2, 3, 4, 5, 6, 7, 8], 'min_child_weight': [1, 2, 5, 10, 15], 'max_delta_step': [0, 1, 2, 5, 10], 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9], 'cosample_bytree': [0.5, 0.6, 0.....1, 1, 100], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'n_estimators': [100, 500, 700, 1000]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search5=RandomizedSearchCV(xgb5,n_iter=15,cv=10,param_distributions=params5,n_jobs=-1,scoring=\"roc_auc\")\n",
    "random_search5.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank 1\n",
      "Mean validation score: 0.928    Std:0.00521\n",
      "Parameters: {'subsample': 0.8, 'scale_pos_weight': 9, 'reg_lambda': 1, 'reg_alpha': 1e-05, 'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 3, 'max_delta_step': 2, 'learning_rate': 0.05, 'gamma': 0.3, 'cosample_bytree': 0.7, 'cosample_bylevel': 0.9}\n",
      "\n",
      "Model with rank 2\n",
      "Mean validation score: 0.927    Std:0.00478\n",
      "Parameters: {'subsample': 0.7, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 1, 'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 2, 'max_delta_step': 5, 'learning_rate': 0.05, 'gamma': 0.0, 'cosample_bytree': 0.5, 'cosample_bylevel': 0.9}\n",
      "\n",
      "Model with rank 3\n",
      "Mean validation score: 0.920    Std:0.00467\n",
      "Parameters: {'subsample': 0.9, 'scale_pos_weight': 9, 'reg_lambda': 1e-05, 'reg_alpha': 0.1, 'n_estimators': 1000, 'min_child_weight': 10, 'max_depth': 3, 'max_delta_step': 1, 'learning_rate': 0.01, 'gamma': 0.4, 'cosample_bytree': 0.6, 'cosample_bylevel': 0.9}\n",
      "\n",
      "Model with rank 4\n",
      "Mean validation score: 0.917    Std:0.00473\n",
      "Parameters: {'subsample': 0.5, 'scale_pos_weight': 2, 'reg_lambda': 100, 'reg_alpha': 0.1, 'n_estimators': 500, 'min_child_weight': 15, 'max_depth': 7, 'max_delta_step': 1, 'learning_rate': 0.01, 'gamma': 0.3, 'cosample_bytree': 0.8, 'cosample_bylevel': 0.5}\n",
      "\n",
      "Model with rank 5\n",
      "Mean validation score: 0.917    Std:0.00498\n",
      "Parameters: {'subsample': 0.9, 'scale_pos_weight': 9, 'reg_lambda': 0.01, 'reg_alpha': 1e-05, 'n_estimators': 500, 'min_child_weight': 10, 'max_depth': 6, 'max_delta_step': 2, 'learning_rate': 0.005, 'gamma': 0.4, 'cosample_bytree': 0.7, 'cosample_bylevel': 0.6}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search5.cv_results_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, cosample_bylevel=0.9,\n",
       "       cosample_bytree=0.7, gamma=0.3, learning_rate=0.05,\n",
       "       max_delta_step=2, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=1000, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=1e-05,\n",
       "       reg_lambda=1, scale_pos_weight=9, seed=None, silent=None,\n",
       "       subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb5=random_search5.best_estimator_\n",
    "xgb5.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.727319587628866"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs=xgb5.predict_proba(x_test1)[:,1]\n",
    "mycutoff=cutoff(y_test1,test_probs)\n",
    "mycutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835611480396575"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes=(test_probs>=mycutoff).astype(int)\n",
    "score=roc_auc_score(y_test1,test_classes)\n",
    "model_scores.append([\"XGBClassifier\",score])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, cosample_bylevel=0.9,\n",
       "       cosample_bytree=0.7, gamma=0.3, learning_rate=0.05,\n",
       "       max_delta_step=2, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=1000, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=1e-05,\n",
       "       reg_lambda=1, scale_pos_weight=9, seed=None, silent=None,\n",
       "       subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb5.fit(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn6=MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "params6={\"learning_rate\":[\"constant\",\"invscaling\",\"adaptive\"],\n",
    "        \"hidden_layer_sizes\":[[5,10,5],[10,20],[5,10,15],[10,15,5],[20,10,5],[20,10,15],[20,10]],\n",
    "        \"alpha\":[0.3,0.1,0.03,0.01],\n",
    "        \"activation\":[\"logistic\",\"relu\",\"tanh\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   41.3s\n",
      "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed:   43.0s\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=-1)]: Done  95 tasks      | elapsed:   43.8s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   43.8s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done  99 tasks      | elapsed:   47.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:   47.6s\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=-1)]: Done 103 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:   51.2s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed:   53.1s\n",
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed:   54.2s\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:   54.4s\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:   54.6s\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed:   55.7s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   56.6s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 118 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 123 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 127 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed:  1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 135 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 139 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 143 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=15, n_jobs=-1,\n",
       "          param_distributions={'learning_rate': ['constant', 'invscaling', 'adaptive'], 'hidden_layer_sizes': [[5, 10, 5], [10, 20], [5, 10, 15], [10, 15, 5], [20, 10, 5], [20, 10, 15], [20, 10]], 'alpha': [0.3, 0.1, 0.03, 0.01], 'activation': ['logistic', 'relu', 'tanh']},\n",
       "          pre_dispatch='2*n_jobs', random_state=2, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=20)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search6=RandomizedSearchCV(nn6,param_distributions=params6,cv=10,n_iter=15,scoring=\"roc_auc\",random_state=2,n_jobs=-1,verbose=20)\n",
    "random_search6.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank 1\n",
      "Mean validation score: 0.611    Std:0.04909\n",
      "Parameters: {'learning_rate': 'constant', 'hidden_layer_sizes': [5, 10, 5], 'alpha': 0.03, 'activation': 'relu'}\n",
      "\n",
      "Model with rank 2\n",
      "Mean validation score: 0.607    Std:0.04102\n",
      "Parameters: {'learning_rate': 'adaptive', 'hidden_layer_sizes': [10, 20], 'alpha': 0.3, 'activation': 'relu'}\n",
      "\n",
      "Model with rank 3\n",
      "Mean validation score: 0.604    Std:0.03971\n",
      "Parameters: {'learning_rate': 'invscaling', 'hidden_layer_sizes': [10, 20], 'alpha': 0.03, 'activation': 'relu'}\n",
      "\n",
      "Model with rank 4\n",
      "Mean validation score: 0.599    Std:0.05473\n",
      "Parameters: {'learning_rate': 'invscaling', 'hidden_layer_sizes': [5, 10, 15], 'alpha': 0.3, 'activation': 'relu'}\n",
      "\n",
      "Model with rank 5\n",
      "Mean validation score: 0.583    Std:0.05567\n",
      "Parameters: {'learning_rate': 'constant', 'hidden_layer_sizes': [10, 15, 5], 'alpha': 0.3, 'activation': 'relu'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search6.cv_results_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.03, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=[5, 10, 5], learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn6=random_search6.best_estimator_\n",
    "nn6.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24237113402061855"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs=nn6.predict_proba(x_test1)[:,1]\n",
    "mycutoff=cutoff(y_test1,test_probs)\n",
    "mycutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5128322929042567"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes=(test_probs>=mycutoff).astype(int)\n",
    "score=roc_auc_score(y_test1,test_classes)\n",
    "model_scores.append([\"NeuralNetwork\",score])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.03, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=[5, 10, 5], learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn6.fit(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.6260010395755664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n=np.arange(5,21)\n",
    "score=0\n",
    "for i in n:\n",
    "    knn7=KNeighborsClassifier(n_neighbors=i)\n",
    "    knn7.fit(x_train1,y_train1)\n",
    "    test_classes=knn7.predict(x_test1)\n",
    "    scr=roc_auc_score(y_test1,test_classes)\n",
    "    if score<scr:\n",
    "        score=scr\n",
    "        n_maxm=i\n",
    "model_scores.append([\"KNeighborsClassifier\",score])\n",
    "print(n_maxm)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn7=KNeighborsClassifier(n_neighbors=n_maxm)\n",
    "knn7.fit(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm8=SVC()\n",
    "svm8.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5128747977180548"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes=svm8.predict(x_test1)\n",
    "score=roc_auc_score(y_test1,test_classes)\n",
    "model_scores.append([\"SVC\",score])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm8.fit(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6004818919251096"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb9=MultinomialNB()\n",
    "nb9.fit(x_train1,y_train1)\n",
    "test_classes=nb9.predict(x_test1)\n",
    "score=roc_auc_score(y_test1,test_classes)\n",
    "model_scores.append([\"Naive_bayes\",score])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb9.fit(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['LogisticRegression', 0.8201600843951002],\n",
       " ['DecisionTreeClassifier', 0.8167600833708879],\n",
       " ['RandomForestClassifier', 0.8247676958294072],\n",
       " ['GradientBoostingClassifier', 0.8365396088532918],\n",
       " ['XGBClassifier', 0.835611480396575],\n",
       " ['NeuralNetwork', 0.5128322929042567],\n",
       " ['KNeighborsClassifier', 0.6260010395755664],\n",
       " ['KNeighborsClassifier', 0.6260010395755664],\n",
       " ['SVC', 0.5128747977180548],\n",
       " ['Naive_bayes', 0.6004818919251096]]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=KNeighborsClassifier(n_neighbors=10)\n",
    "clf2=RandomForestClassifier(class_weight=None,n_estimators=500)\n",
    "clf3=RandomForestClassifier(class_weight=None,n_estimators=1000)\n",
    "clf4=RandomForestClassifier(class_weight=\"balanced\",n_estimators=700)\n",
    "clf5=XGBClassifier(n_estimators=700,objective=\"binary:logistic\",learning_rate=0.1)\n",
    "clf6=XGBClassifier(n_estimators=500,objective=\"binary:logistic\",learning_rate=0.05)\n",
    "clf7=GradientBoostingClassifier(n_estimators=700,learning_rate=0.05)\n",
    "Algos={clf1,clf2,clf3,clf4,clf5,clf6,clf7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=x_train1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf1</th>\n",
       "      <th>clf2</th>\n",
       "      <th>clf3</th>\n",
       "      <th>clf4</th>\n",
       "      <th>clf5</th>\n",
       "      <th>clf6</th>\n",
       "      <th>clf7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26019</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26020</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26021</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26022</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26023</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26024</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26025</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26026</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26027</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26028</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26029</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26030</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26031</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26032</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26033</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26034</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26035</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26036</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26037</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26038</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26039</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26040</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26041</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26042</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26043</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26044</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26045</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26046</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26047</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26048 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       clf1  clf2  clf3  clf4  clf5  clf6  clf7\n",
       "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "5       0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "6       0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "7       0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "8       0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "9       0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "10      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "11      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "12      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "13      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "14      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "15      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "16      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "17      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "18      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "19      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "20      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "21      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "22      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "23      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "24      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "25      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "27      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "28      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "29      0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "...     ...   ...   ...   ...   ...   ...   ...\n",
       "26018   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26019   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26020   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26021   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26022   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26023   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26024   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26025   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26026   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26027   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26028   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26029   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26030   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26031   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26032   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26033   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26034   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26035   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26036   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26037   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26038   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26039   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26040   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26041   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26042   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26043   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26044   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26045   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26046   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "26047   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "\n",
       "[26048 rows x 7 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1=pd.DataFrame({\"clf1\":np.zeros(rows),\"clf2\":np.zeros(rows),\"clf3\":np.zeros(rows),\n",
    "                   \"clf4\":np.zeros(rows),\"clf5\":np.zeros(rows),\"clf6\":np.zeros(rows),\"clf7\":np.zeros(rows)})\n",
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold number: 1\n",
      "Algo number: 1\n",
      "Algo number: 2\n",
      "Algo number: 3\n",
      "Algo number: 4\n",
      "Algo number: 5\n",
      "Algo number: 6\n",
      "Algo number: 7\n",
      "fold number: 2\n",
      "Algo number: 1\n",
      "Algo number: 2\n",
      "Algo number: 3\n",
      "Algo number: 4\n",
      "Algo number: 5\n",
      "Algo number: 6\n",
      "Algo number: 7\n",
      "fold number: 3\n",
      "Algo number: 1\n",
      "Algo number: 2\n",
      "Algo number: 3\n",
      "Algo number: 4\n",
      "Algo number: 5\n",
      "Algo number: 6\n",
      "Algo number: 7\n",
      "fold number: 4\n",
      "Algo number: 1\n",
      "Algo number: 2\n",
      "Algo number: 3\n",
      "Algo number: 4\n",
      "Algo number: 5\n",
      "Algo number: 6\n",
      "Algo number: 7\n",
      "fold number: 5\n",
      "Algo number: 1\n",
      "Algo number: 2\n",
      "Algo number: 3\n",
      "Algo number: 4\n",
      "Algo number: 5\n",
      "Algo number: 6\n",
      "Algo number: 7\n",
      "fold number: 6\n",
      "Algo number: 1\n",
      "Algo number: 2\n",
      "Algo number: 3\n",
      "Algo number: 4\n",
      "Algo number: 5\n",
      "Algo number: 6\n",
      "Algo number: 7\n",
      "fold number: 7\n",
      "Algo number: 1\n",
      "Algo number: 2\n",
      "Algo number: 3\n",
      "Algo number: 4\n",
      "Algo number: 5\n",
      "Algo number: 6\n",
      "Algo number: 7\n",
      "fold number: 8\n",
      "Algo number: 1\n",
      "Algo number: 2\n",
      "Algo number: 3\n",
      "Algo number: 4\n",
      "Algo number: 5\n",
      "Algo number: 6\n",
      "Algo number: 7\n",
      "fold number: 9\n",
      "Algo number: 1\n",
      "Algo number: 2\n",
      "Algo number: 3\n",
      "Algo number: 4\n",
      "Algo number: 5\n",
      "Algo number: 6\n",
      "Algo number: 7\n",
      "fold number: 10\n",
      "Algo number: 1\n",
      "Algo number: 2\n",
      "Algo number: 3\n",
      "Algo number: 4\n",
      "Algo number: 5\n",
      "Algo number: 6\n",
      "Algo number: 7\n"
     ]
    }
   ],
   "source": [
    "fold=1\n",
    "for train,test in kf.split(x_train1):\n",
    "    print(\"fold number:\",fold)\n",
    "    \n",
    "    for i,clf in enumerate(Algos):\n",
    "        print(\"Algo number:\",i+1)\n",
    "        x_train_train=x_train1.loc[train]\n",
    "        y_train_train=y_train1[train]\n",
    "        x_train_test=x_train1.loc[test]\n",
    "        \n",
    "        clf.fit(x_train_train,y_train_train)\n",
    "        p=clf.predict_proba(x_train_test)[:,1]\n",
    "        layer1.iloc[test,i]=p\n",
    "    fold+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf1</th>\n",
       "      <th>clf2</th>\n",
       "      <th>clf3</th>\n",
       "      <th>clf4</th>\n",
       "      <th>clf5</th>\n",
       "      <th>clf6</th>\n",
       "      <th>clf7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.142888</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.127136</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.111932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.002812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.327521</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.313434</td>\n",
       "      <td>0.204286</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.327378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.044558</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.042114</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.022247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.360300</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.348293</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.392262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.453971</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.486328</td>\n",
       "      <td>0.854286</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.523636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.066029</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.067818</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.097484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.726733</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.768492</td>\n",
       "      <td>0.717143</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.714477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.100475</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.096322</td>\n",
       "      <td>0.097143</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.101734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.342164</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.340808</td>\n",
       "      <td>0.127143</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.388561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.036643</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.002189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013312</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>0.017143</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.006466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.858914</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.872282</td>\n",
       "      <td>0.752857</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.902933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363911</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.323140</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.318151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.053920</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.045090</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.041338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.816266</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.844143</td>\n",
       "      <td>0.781429</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.825604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.359270</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.386976</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.410427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.801709</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.824286</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.801061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.009839</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.261064</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.228206</td>\n",
       "      <td>0.294286</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.260516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.025137</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.026372</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.019926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.108658</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.104316</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010936</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.012267</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.010671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.012155</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.015973</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998870</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.999729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26018</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.053833</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.046699</td>\n",
       "      <td>0.122857</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.048281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26019</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.639741</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.633412</td>\n",
       "      <td>0.411429</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.643780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26020</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.271644</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.234896</td>\n",
       "      <td>0.262857</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.258805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26021</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26022</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.517882</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.485327</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.487547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26023</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.044467</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.033496</td>\n",
       "      <td>0.052857</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.021209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26024</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.007825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26025</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26026</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26027</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.042285</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.055076</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.012705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26028</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.600620</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.566801</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.444932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26029</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.084653</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.085033</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.073643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26030</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090284</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.079028</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.094482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26031</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.285821</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.387726</td>\n",
       "      <td>0.225714</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.578411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26032</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.985725</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.983924</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.994023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26033</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.008694</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26034</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.385331</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.374403</td>\n",
       "      <td>0.195714</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.369738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26035</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26036</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.203928</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.193621</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.175303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26037</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26038</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.048128</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.039518</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26039</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.028835</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.025276</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.020266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26040</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060657</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.059164</td>\n",
       "      <td>0.134286</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.048286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26041</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.985673</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.992122</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.997790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26042</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025401</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.021870</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26043</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.993804</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.993046</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.996219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26044</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.149045</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.123525</td>\n",
       "      <td>0.224286</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.133190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26045</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.927367</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.963743</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.974971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26046</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26047</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.057870</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.061153</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.069910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26048 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       clf1      clf2   clf3      clf4      clf5   clf6      clf7\n",
       "0       0.3  0.142888  0.110  0.127136  0.142857  0.112  0.111932\n",
       "1       0.2  0.006984  0.014  0.007446  0.012857  0.016  0.002812\n",
       "2       0.0  0.001101  0.001  0.003686  0.001429  0.000  0.000316\n",
       "3       0.3  0.327521  0.192  0.313434  0.204286  0.224  0.327378\n",
       "4       0.1  0.044558  0.007  0.042114  0.001429  0.002  0.022247\n",
       "5       0.1  0.000540  0.000  0.002427  0.000000  0.000  0.000109\n",
       "6       0.0  0.360300  0.179  0.348293  0.190000  0.208  0.392262\n",
       "7       0.2  0.453971  0.817  0.486328  0.854286  0.832  0.523636\n",
       "8       0.1  0.066029  0.010  0.067818  0.008571  0.010  0.097484\n",
       "9       0.5  0.007442  0.000  0.013077  0.000000  0.000  0.008582\n",
       "10      0.3  0.726733  0.724  0.768492  0.717143  0.700  0.714477\n",
       "11      0.4  0.100475  0.105  0.096322  0.097143  0.116  0.101734\n",
       "12      0.2  0.342164  0.129  0.340808  0.127143  0.132  0.388561\n",
       "13      0.1  0.016658  0.104  0.036643  0.085714  0.104  0.002189\n",
       "14      0.0  0.013312  0.024  0.036158  0.017143  0.020  0.006466\n",
       "15      0.2  0.858914  0.759  0.872282  0.752857  0.736  0.902933\n",
       "16      0.0  0.363911  0.410  0.323140  0.357143  0.428  0.318151\n",
       "17      0.4  0.053920  0.008  0.045090  0.008571  0.012  0.041338\n",
       "18      0.4  0.816266  0.802  0.844143  0.781429  0.786  0.825604\n",
       "19      0.1  0.359270  0.338  0.386976  0.350000  0.388  0.410427\n",
       "20      0.1  0.801709  0.849  0.841053  0.824286  0.840  0.801061\n",
       "21      0.0  0.000881  0.000  0.003687  0.000000  0.000  0.000252\n",
       "22      0.1  0.008334  0.008  0.009839  0.011429  0.020  0.004500\n",
       "23      0.2  0.261064  0.328  0.228206  0.294286  0.296  0.260516\n",
       "24      0.3  0.025137  0.008  0.026372  0.008571  0.010  0.019926\n",
       "25      0.2  0.001173  0.000  0.002191  0.000000  0.000  0.000744\n",
       "26      0.3  0.108658  0.042  0.104316  0.064286  0.044  0.124248\n",
       "27      0.3  0.010936  0.007  0.012267  0.004286  0.004  0.010671\n",
       "28      0.9  0.012155  0.006  0.015973  0.004286  0.006  0.006471\n",
       "29      1.0  0.998870  0.992  0.995117  0.985714  0.988  0.999729\n",
       "...     ...       ...    ...       ...       ...    ...       ...\n",
       "26018   0.3  0.053833  0.136  0.046699  0.122857  0.152  0.048281\n",
       "26019   0.2  0.639741  0.396  0.633412  0.411429  0.408  0.643780\n",
       "26020   0.2  0.271644  0.206  0.234896  0.262857  0.230  0.258805\n",
       "26021   0.0  0.000305  0.000  0.001018  0.000000  0.000  0.000100\n",
       "26022   0.5  0.517882  0.346  0.485327  0.340000  0.326  0.487547\n",
       "26023   0.2  0.044467  0.077  0.033496  0.052857  0.072  0.021209\n",
       "26024   0.2  0.011191  0.001  0.009761  0.001429  0.002  0.007825\n",
       "26025   0.1  0.000269  0.000  0.001092  0.000000  0.000  0.000070\n",
       "26026   0.0  0.000439  0.000  0.001203  0.000000  0.000  0.000259\n",
       "26027   0.3  0.042285  0.145  0.055076  0.130000  0.138  0.012705\n",
       "26028   0.1  0.600620  0.529  0.566801  0.542857  0.528  0.444932\n",
       "26029   0.3  0.084653  0.025  0.085033  0.021429  0.026  0.073643\n",
       "26030   0.0  0.090284  0.151  0.079028  0.085714  0.174  0.094482\n",
       "26031   0.2  0.285821  0.280  0.387726  0.225714  0.270  0.578411\n",
       "26032   0.9  0.985725  0.955  0.983924  0.914286  0.946  0.994023\n",
       "26033   0.3  0.008694  0.000  0.008091  0.000000  0.000  0.002023\n",
       "26034   0.2  0.385331  0.190  0.374403  0.195714  0.180  0.369738\n",
       "26035   0.4  0.000174  0.000  0.000968  0.000000  0.000  0.000073\n",
       "26036   0.2  0.203928  0.299  0.193621  0.300000  0.314  0.175303\n",
       "26037   0.3  0.002083  0.005  0.004070  0.000000  0.008  0.000546\n",
       "26038   0.2  0.048128  0.003  0.039518  0.005714  0.008  0.047000\n",
       "26039   0.1  0.028835  0.014  0.025276  0.007143  0.012  0.020266\n",
       "26040   0.0  0.060657  0.135  0.059164  0.134286  0.142  0.048286\n",
       "26041   0.8  0.985673  0.983  0.992122  0.981429  0.982  0.997790\n",
       "26042   0.0  0.025401  0.001  0.021870  0.002857  0.000  0.012629\n",
       "26043   0.3  0.993804  0.939  0.993046  0.931429  0.916  0.996219\n",
       "26044   0.2  0.149045  0.193  0.123525  0.224286  0.196  0.133190\n",
       "26045   0.6  0.927367  0.603  0.963743  0.600000  0.642  0.974971\n",
       "26046   0.2  0.000910  0.004  0.002391  0.004286  0.002  0.000071\n",
       "26047   0.2  0.057870  0.005  0.061153  0.008571  0.014  0.069910\n",
       "\n",
       "[26048 rows x 7 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=x_test1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2_test=pd.DataFrame({\"clf1\":np.zeros(rows),\"clf2\":np.zeros(rows),\"clf3\":np.zeros(rows),\n",
    "                   \"clf4\":np.zeros(rows),\"clf5\":np.zeros(rows),\"clf6\":np.zeros(rows),\"clf7\":np.zeros(rows)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algo number 1\n",
      "Algo number 2\n",
      "Algo number 3\n",
      "Algo number 4\n",
      "Algo number 5\n",
      "Algo number 6\n",
      "Algo number 7\n"
     ]
    }
   ],
   "source": [
    "for i,clf in enumerate(Algos):\n",
    "    print(\"Algo number\",i+1)\n",
    "    clf.fit(x_train1,y_train1)\n",
    "    p=clf.predict_proba(x_test1)[:,1]\n",
    "    layer2_test.iloc[:,i]=p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf1</th>\n",
       "      <th>clf2</th>\n",
       "      <th>clf3</th>\n",
       "      <th>clf4</th>\n",
       "      <th>clf5</th>\n",
       "      <th>clf6</th>\n",
       "      <th>clf7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.142888</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.127136</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.111932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.002812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.327521</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.313434</td>\n",
       "      <td>0.204286</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.327378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.044558</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.042114</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.022247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.360300</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.348293</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.392262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.453971</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.486328</td>\n",
       "      <td>0.854286</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.523636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.066029</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.067818</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.097484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.726733</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.768492</td>\n",
       "      <td>0.717143</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.714477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.100475</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.096322</td>\n",
       "      <td>0.097143</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.101734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.342164</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.340808</td>\n",
       "      <td>0.127143</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.388561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.036643</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.002189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013312</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>0.017143</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.006466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.858914</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.872282</td>\n",
       "      <td>0.752857</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.902933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363911</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.323140</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.318151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.053920</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.045090</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.041338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.816266</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.844143</td>\n",
       "      <td>0.781429</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.825604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.359270</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.386976</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.410427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.801709</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.824286</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.801061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.009839</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.261064</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.228206</td>\n",
       "      <td>0.294286</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.260516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.025137</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.026372</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.019926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.108658</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.104316</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.124248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010936</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.012267</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.010671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.012155</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.015973</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998870</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.999729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26018</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.053833</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.046699</td>\n",
       "      <td>0.122857</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.048281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26019</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.639741</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.633412</td>\n",
       "      <td>0.411429</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.643780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26020</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.271644</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.234896</td>\n",
       "      <td>0.262857</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.258805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26021</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26022</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.517882</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.485327</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.487547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26023</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.044467</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.033496</td>\n",
       "      <td>0.052857</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.021209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26024</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.007825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26025</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26026</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26027</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.042285</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.055076</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.012705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26028</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.600620</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.566801</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.444932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26029</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.084653</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.085033</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.073643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26030</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090284</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.079028</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.094482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26031</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.285821</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.387726</td>\n",
       "      <td>0.225714</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.578411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26032</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.985725</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.983924</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.994023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26033</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.008694</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26034</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.385331</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.374403</td>\n",
       "      <td>0.195714</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.369738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26035</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26036</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.203928</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.193621</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.175303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26037</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26038</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.048128</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.039518</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26039</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.028835</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.025276</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.020266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26040</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060657</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.059164</td>\n",
       "      <td>0.134286</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.048286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26041</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.985673</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.992122</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.997790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26042</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025401</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.021870</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26043</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.993804</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.993046</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.996219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26044</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.149045</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.123525</td>\n",
       "      <td>0.224286</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.133190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26045</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.927367</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.963743</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.974971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26046</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26047</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.057870</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.061153</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.069910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26048 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       clf1      clf2   clf3      clf4      clf5   clf6      clf7\n",
       "0       0.3  0.142888  0.110  0.127136  0.142857  0.112  0.111932\n",
       "1       0.2  0.006984  0.014  0.007446  0.012857  0.016  0.002812\n",
       "2       0.0  0.001101  0.001  0.003686  0.001429  0.000  0.000316\n",
       "3       0.3  0.327521  0.192  0.313434  0.204286  0.224  0.327378\n",
       "4       0.1  0.044558  0.007  0.042114  0.001429  0.002  0.022247\n",
       "5       0.1  0.000540  0.000  0.002427  0.000000  0.000  0.000109\n",
       "6       0.0  0.360300  0.179  0.348293  0.190000  0.208  0.392262\n",
       "7       0.2  0.453971  0.817  0.486328  0.854286  0.832  0.523636\n",
       "8       0.1  0.066029  0.010  0.067818  0.008571  0.010  0.097484\n",
       "9       0.5  0.007442  0.000  0.013077  0.000000  0.000  0.008582\n",
       "10      0.3  0.726733  0.724  0.768492  0.717143  0.700  0.714477\n",
       "11      0.4  0.100475  0.105  0.096322  0.097143  0.116  0.101734\n",
       "12      0.2  0.342164  0.129  0.340808  0.127143  0.132  0.388561\n",
       "13      0.1  0.016658  0.104  0.036643  0.085714  0.104  0.002189\n",
       "14      0.0  0.013312  0.024  0.036158  0.017143  0.020  0.006466\n",
       "15      0.2  0.858914  0.759  0.872282  0.752857  0.736  0.902933\n",
       "16      0.0  0.363911  0.410  0.323140  0.357143  0.428  0.318151\n",
       "17      0.4  0.053920  0.008  0.045090  0.008571  0.012  0.041338\n",
       "18      0.4  0.816266  0.802  0.844143  0.781429  0.786  0.825604\n",
       "19      0.1  0.359270  0.338  0.386976  0.350000  0.388  0.410427\n",
       "20      0.1  0.801709  0.849  0.841053  0.824286  0.840  0.801061\n",
       "21      0.0  0.000881  0.000  0.003687  0.000000  0.000  0.000252\n",
       "22      0.1  0.008334  0.008  0.009839  0.011429  0.020  0.004500\n",
       "23      0.2  0.261064  0.328  0.228206  0.294286  0.296  0.260516\n",
       "24      0.3  0.025137  0.008  0.026372  0.008571  0.010  0.019926\n",
       "25      0.2  0.001173  0.000  0.002191  0.000000  0.000  0.000744\n",
       "26      0.3  0.108658  0.042  0.104316  0.064286  0.044  0.124248\n",
       "27      0.3  0.010936  0.007  0.012267  0.004286  0.004  0.010671\n",
       "28      0.9  0.012155  0.006  0.015973  0.004286  0.006  0.006471\n",
       "29      1.0  0.998870  0.992  0.995117  0.985714  0.988  0.999729\n",
       "...     ...       ...    ...       ...       ...    ...       ...\n",
       "26018   0.3  0.053833  0.136  0.046699  0.122857  0.152  0.048281\n",
       "26019   0.2  0.639741  0.396  0.633412  0.411429  0.408  0.643780\n",
       "26020   0.2  0.271644  0.206  0.234896  0.262857  0.230  0.258805\n",
       "26021   0.0  0.000305  0.000  0.001018  0.000000  0.000  0.000100\n",
       "26022   0.5  0.517882  0.346  0.485327  0.340000  0.326  0.487547\n",
       "26023   0.2  0.044467  0.077  0.033496  0.052857  0.072  0.021209\n",
       "26024   0.2  0.011191  0.001  0.009761  0.001429  0.002  0.007825\n",
       "26025   0.1  0.000269  0.000  0.001092  0.000000  0.000  0.000070\n",
       "26026   0.0  0.000439  0.000  0.001203  0.000000  0.000  0.000259\n",
       "26027   0.3  0.042285  0.145  0.055076  0.130000  0.138  0.012705\n",
       "26028   0.1  0.600620  0.529  0.566801  0.542857  0.528  0.444932\n",
       "26029   0.3  0.084653  0.025  0.085033  0.021429  0.026  0.073643\n",
       "26030   0.0  0.090284  0.151  0.079028  0.085714  0.174  0.094482\n",
       "26031   0.2  0.285821  0.280  0.387726  0.225714  0.270  0.578411\n",
       "26032   0.9  0.985725  0.955  0.983924  0.914286  0.946  0.994023\n",
       "26033   0.3  0.008694  0.000  0.008091  0.000000  0.000  0.002023\n",
       "26034   0.2  0.385331  0.190  0.374403  0.195714  0.180  0.369738\n",
       "26035   0.4  0.000174  0.000  0.000968  0.000000  0.000  0.000073\n",
       "26036   0.2  0.203928  0.299  0.193621  0.300000  0.314  0.175303\n",
       "26037   0.3  0.002083  0.005  0.004070  0.000000  0.008  0.000546\n",
       "26038   0.2  0.048128  0.003  0.039518  0.005714  0.008  0.047000\n",
       "26039   0.1  0.028835  0.014  0.025276  0.007143  0.012  0.020266\n",
       "26040   0.0  0.060657  0.135  0.059164  0.134286  0.142  0.048286\n",
       "26041   0.8  0.985673  0.983  0.992122  0.981429  0.982  0.997790\n",
       "26042   0.0  0.025401  0.001  0.021870  0.002857  0.000  0.012629\n",
       "26043   0.3  0.993804  0.939  0.993046  0.931429  0.916  0.996219\n",
       "26044   0.2  0.149045  0.193  0.123525  0.224286  0.196  0.133190\n",
       "26045   0.6  0.927367  0.603  0.963743  0.600000  0.642  0.974971\n",
       "26046   0.2  0.000910  0.004  0.002391  0.004286  0.002  0.000071\n",
       "26047   0.2  0.057870  0.005  0.061153  0.008571  0.014  0.069910\n",
       "\n",
       "[26048 rows x 7 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf1</th>\n",
       "      <th>clf2</th>\n",
       "      <th>clf3</th>\n",
       "      <th>clf4</th>\n",
       "      <th>clf5</th>\n",
       "      <th>clf6</th>\n",
       "      <th>clf7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.033568</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.027175</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.020208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.023147</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.031104</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.013138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.583805</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.562301</td>\n",
       "      <td>0.325714</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.581185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.303439</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.273679</td>\n",
       "      <td>0.174286</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.290679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.027035</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.027957</td>\n",
       "      <td>0.062857</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.030334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.640055</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.767647</td>\n",
       "      <td>0.672857</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.805361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.784947</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.812139</td>\n",
       "      <td>0.744286</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.800250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.115509</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.166857</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.190367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.983622</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.986927</td>\n",
       "      <td>0.872857</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.992917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.043510</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.036653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.011877</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.021304</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.011908</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.022570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.059594</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.058955</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.047355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.015182</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.009980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.727532</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.762951</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.750666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998343</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.992987</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.999727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.055632</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.074215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.086451</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.118571</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.101785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018282</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.015241</td>\n",
       "      <td>0.017143</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.011869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.662969</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.680468</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.680555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.060019</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.042251</td>\n",
       "      <td>0.041429</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.039048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.230143</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.208639</td>\n",
       "      <td>0.394286</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.210113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.161319</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.152516</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.266520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.026652</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.029318</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.039246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405780</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.410435</td>\n",
       "      <td>0.105714</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.390675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6483</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.079420</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.070356</td>\n",
       "      <td>0.101429</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.061173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.040784</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.031795</td>\n",
       "      <td>0.038571</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.027142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.061212</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.060408</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.055195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6487</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.036373</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.069364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.472309</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.556249</td>\n",
       "      <td>0.402857</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.417409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.566976</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.531696</td>\n",
       "      <td>0.631429</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.524317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.171069</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.254286</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.317478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.553415</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.532723</td>\n",
       "      <td>0.467143</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.547998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.011424</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238540</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.190706</td>\n",
       "      <td>0.081429</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.209517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.439352</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.452043</td>\n",
       "      <td>0.105714</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.448930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505228</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.529816</td>\n",
       "      <td>0.412857</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.502411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.436184</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.454485</td>\n",
       "      <td>0.447143</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.469047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6499</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6500</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.990257</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.991418</td>\n",
       "      <td>0.995714</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.995776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6501</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.011065</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.009915</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.011685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6502</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.989376</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.990237</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.995862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6503</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6504</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.035558</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.038773</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.028647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6505</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.043683</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.045597</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.030326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6507</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.115343</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.082770</td>\n",
       "      <td>0.081429</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.086516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.011853</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.009311</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.006464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.981530</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.987409</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.985520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6510</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.948416</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.973389</td>\n",
       "      <td>0.987143</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.987841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6511</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6512</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.019747</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.017307</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6513 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      clf1      clf2   clf3      clf4      clf5   clf6      clf7\n",
       "0      0.3  0.033568  0.020  0.027175  0.010000  0.008  0.020208\n",
       "1      0.1  0.023147  0.005  0.031104  0.004286  0.006  0.013138\n",
       "2      0.1  0.583805  0.281  0.562301  0.325714  0.258  0.581185\n",
       "3      0.2  0.303439  0.180  0.273679  0.174286  0.180  0.290679\n",
       "4      0.3  0.027035  0.075  0.027957  0.062857  0.062  0.030334\n",
       "5      0.3  0.640055  0.749  0.767647  0.672857  0.704  0.805361\n",
       "6      0.4  0.784947  0.718  0.812139  0.744286  0.732  0.800250\n",
       "7      0.1  0.115509  0.196  0.166857  0.157143  0.194  0.190367\n",
       "8      0.6  0.983622  0.888  0.986927  0.872857  0.850  0.992917\n",
       "9      0.1  0.032432  0.026  0.043510  0.027143  0.026  0.036653\n",
       "10     0.6  0.011877  0.006  0.015412  0.008571  0.000  0.008527\n",
       "11     0.1  0.021304  0.074  0.011908  0.055714  0.040  0.022570\n",
       "12     0.4  0.059594  0.046  0.058955  0.060000  0.040  0.047355\n",
       "13     0.1  0.000255  0.000  0.001266  0.000000  0.000  0.000075\n",
       "14     0.1  0.015182  0.013  0.014696  0.020000  0.016  0.009980\n",
       "15     0.1  0.000729  0.002  0.001278  0.000000  0.000  0.000126\n",
       "16     0.3  0.727532  0.728  0.762951  0.765714  0.716  0.750666\n",
       "17     1.0  0.998343  0.969  0.992987  0.964286  0.962  0.999727\n",
       "18     0.3  0.055632  0.024  0.071162  0.034286  0.026  0.074215\n",
       "19     0.5  0.086451  0.158  0.075943  0.118571  0.132  0.101785\n",
       "20     0.0  0.018282  0.011  0.015241  0.017143  0.022  0.011869\n",
       "21     0.0  0.004755  0.001  0.004167  0.008571  0.004  0.002023\n",
       "22     0.1  0.662969  0.786  0.680468  0.765714  0.802  0.680555\n",
       "23     0.1  0.000481  0.000  0.001892  0.001429  0.002  0.000177\n",
       "24     0.1  0.060019  0.048  0.042251  0.041429  0.026  0.039048\n",
       "25     0.0  0.000307  0.000  0.001573  0.000000  0.000  0.000071\n",
       "26     0.6  0.230143  0.387  0.208639  0.394286  0.402  0.210113\n",
       "27     0.8  0.161319  0.188  0.152516  0.192857  0.190  0.266520\n",
       "28     0.3  0.026652  0.010  0.029318  0.007143  0.010  0.039246\n",
       "29     0.0  0.405780  0.174  0.410435  0.105714  0.156  0.390675\n",
       "...    ...       ...    ...       ...       ...    ...       ...\n",
       "6483   0.1  0.008093  0.000  0.006648  0.000000  0.002  0.004857\n",
       "6484   0.2  0.079420  0.101  0.070356  0.101429  0.108  0.061173\n",
       "6485   0.1  0.040784  0.033  0.031795  0.038571  0.042  0.027142\n",
       "6486   0.3  0.061212  0.161  0.060408  0.140000  0.158  0.055195\n",
       "6487   0.0  0.007525  0.002  0.005022  0.000000  0.000  0.001537\n",
       "6488   0.1  0.000588  0.000  0.002308  0.000000  0.000  0.000190\n",
       "6489   0.2  0.040449  0.011  0.036373  0.007143  0.012  0.069364\n",
       "6490   0.2  0.472309  0.393  0.556249  0.402857  0.402  0.417409\n",
       "6491   0.1  0.566976  0.594  0.531696  0.631429  0.578  0.524317\n",
       "6492   0.1  0.171069  0.273  0.199146  0.254286  0.274  0.317478\n",
       "6493   0.3  0.553415  0.495  0.532723  0.467143  0.494  0.547998\n",
       "6494   0.4  0.010298  0.003  0.011424  0.002857  0.006  0.005362\n",
       "6495   0.0  0.238540  0.075  0.190706  0.081429  0.070  0.209517\n",
       "6496   0.4  0.439352  0.108  0.452043  0.105714  0.124  0.448930\n",
       "6497   0.0  0.505228  0.504  0.529816  0.412857  0.436  0.502411\n",
       "6498   0.2  0.436184  0.419  0.454485  0.447143  0.436  0.469047\n",
       "6499   0.4  0.003525  0.006  0.003449  0.000000  0.002  0.001110\n",
       "6500   0.3  0.990257  0.996  0.991418  0.995714  0.996  0.995776\n",
       "6501   0.2  0.011065  0.102  0.009915  0.091429  0.082  0.011685\n",
       "6502   0.4  0.989376  0.969  0.990237  0.970000  0.966  0.995862\n",
       "6503   0.2  0.000323  0.000  0.001538  0.000000  0.000  0.000095\n",
       "6504   0.1  0.035558  0.008  0.038773  0.007143  0.008  0.028647\n",
       "6505   0.1  0.043683  0.011  0.045597  0.020000  0.014  0.030326\n",
       "6506   0.1  0.003494  0.006  0.003861  0.004286  0.004  0.001377\n",
       "6507   0.3  0.115343  0.083  0.082770  0.081429  0.072  0.086516\n",
       "6508   0.1  0.011853  0.002  0.009311  0.001429  0.008  0.006464\n",
       "6509   0.6  0.981530  0.991  0.987409  0.991429  0.986  0.985520\n",
       "6510   0.3  0.948416  0.978  0.973389  0.987143  0.980  0.987841\n",
       "6511   0.1  0.005085  0.000  0.006681  0.000000  0.000  0.004172\n",
       "6512   0.2  0.019747  0.032  0.017307  0.028571  0.022  0.024373\n",
       "\n",
       "[6513 rows x 7 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr=LogisticRegression(class_weight=\"balanced\")\n",
    "logr.fit(layer1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4141237113402062"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs=logr.predict_proba(layer2_test)[:,1]\n",
    "mycutoff=cutoff(y_test1,test_probs)\n",
    "mycutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8404280311565406"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes=(mycutoff<=test_probs).astype(int)\n",
    "score=roc_auc_score(y_test1,test_classes)\n",
    "model_scores.append([\"stacking\",score])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.fit(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['LogisticRegression', 0.8201600843951002],\n",
       " ['DecisionTreeClassifier', 0.8167600833708879],\n",
       " ['RandomForestClassifier', 0.8247676958294072],\n",
       " ['GradientBoostingClassifier', 0.8365396088532918],\n",
       " ['XGBClassifier', 0.835611480396575],\n",
       " ['NeuralNetwork', 0.5128322929042567],\n",
       " ['KNeighborsClassifier', 0.6260010395755664],\n",
       " ['KNeighborsClassifier', 0.6260010395755664],\n",
       " ['SVC', 0.5128747977180548],\n",
       " ['Naive_bayes', 0.6004818919251096],\n",
       " ['stacking', 0.8404280311565406]]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_model1.pkl']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(logr,'my_model1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_model1.pkl']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(rf3,'my_model1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
